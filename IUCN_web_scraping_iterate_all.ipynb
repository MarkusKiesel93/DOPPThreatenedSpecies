{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "from time import sleep\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for Taxonomy group Animalia\n",
    "def filter_animals(filters):\n",
    "    filter_taxonomy = filters.find_element_by_xpath(\"//*[text()='Taxonomy']\")\n",
    "    filter_taxonomy.click() # click section\n",
    "    sleep(2)\n",
    "    filter_animals = filters.find_element_by_xpath(\"//*[text()='Animalia']\")\n",
    "    filter_animals.click()  # click animals section\n",
    "    filter_taxonomy.click() # collapse filter"
   ]
  },
  {
   "source": [
    "### Why filter country legends ?\n",
    "https://www.iucnredlist.org/resources/summary-statistics\n",
    "\n",
    "Important note: the figures presented in Tables 5 and 6 differ from the default setting for country searches on the website. The default search includes ALL occurrences within each country (i.e., including introduced species, vagrant records, etc.). To modify country searches on the website to match the tables below, use the Country Legends filters on the Advanced Search page to show species tagged as 'Extant', 'Extant & Reintroduced', 'Extinct', 'Extinct & Reintroduced', 'Possibly Extinct', and 'Possibly Extinct & Reintroduced'."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter country legends\n",
    "def filter_country_legends(filters, filter_items):\n",
    "    filter_country_legends = filters.find_element_by_xpath(\"//*[text()='Country Legends']\")\n",
    "    filter_country_legends.click()  # click section\n",
    "    sleep(2)\n",
    "    for item in filter_items:\n",
    "        element = filters.find_element_by_xpath(f\"//*[text()='{item}']\")\n",
    "        element.click()   # click items in list\n",
    "    filter_country_legends.click()  # collapse filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all regions from section \"land Regions\"\n",
    "# click is needed for first call\n",
    "def get_regions(filters, click=False):\n",
    "    land_region = filters.find_element_by_xpath(\"//*[text()='Land Regions']\")\n",
    "    if click:\n",
    "        land_region.click()\n",
    "    # get section (parent element)\n",
    "    filter_section = land_region.find_element_by_xpath(\"..\")\n",
    "    # get all regions\n",
    "    regions = filter_section.find_elements_by_class_name('filter__list__item')\n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all countrys from a region\n",
    "def get_countries(filters):\n",
    "    filter_region = filters.find_element_by_xpath(\"//*[text()='Land Regions']\")\n",
    "    # get section (parent element)\n",
    "    filter_section = filter_region.find_element_by_xpath(\"..\")\n",
    "    # get all list items\n",
    "    country_items = filter_section.find_element_by_class_name('filter__list__item')\n",
    "    country_items = country_items.find_elements_by_class_name('filter__list__item')\n",
    "    # extract label\n",
    "    countries = []\n",
    "    for element in country_items[1:]:\n",
    "        countries.append(element.find_element_by_tag_name('label'))\n",
    "    return countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click the \"Land Regions\" button to return to all filters\n",
    "def click_return_regions(filters):\n",
    "    # select second element with name \"Land Regions\"\n",
    "    filter_region = filters.find_elements_by_xpath(\"//*[text()='Land Regions']\")[1]\n",
    "    filter_region.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click a filter for \"Land Regions\"\n",
    "# offset is needed to click the arrow on the right instead of the checkbox\n",
    "def click_filter(driver, element, offset=False):\n",
    "    x_offset = 0\n",
    "    if offset:\n",
    "        x_offset = 115\n",
    "    ac = ActionChains(driver)\n",
    "    ac.move_to_element(element).move_by_offset(x_offset, 0).click().perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clickst the \"show all\" button on the bottom of the main content as long as all species are loaded\n",
    "def load_all(driver):\n",
    "    main_content = driver.find_element_by_class_name('layout-page__major')\n",
    "    try:\n",
    "        show_all_button = main_content.find_element_by_class_name('section__link-out')\n",
    "        show_all_button.click()\n",
    "        # todo: find better method to wait for loaded content\n",
    "        sleep(10)\n",
    "        load_all(driver) # recursive call\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract species info from html li items\n",
    "def extract_content(driver):\n",
    "    results = []\n",
    "    \n",
    "    # get main html content\n",
    "    main_content = driver.find_element_by_class_name('layout-page__major')\n",
    "    main_html = main_content.get_attribute('innerHTML')\n",
    "    \n",
    "    # get html with beautifulsoup\n",
    "    soup = BeautifulSoup(main_html, 'html.parser')\n",
    "    items = soup.find_all('li', class_='list-results__item')\n",
    "    for item in items:\n",
    "        result = {}\n",
    "        result['kingdom_class'] = item.contents[0].string\n",
    "        result['common_name'] = item.contents[1].text\n",
    "        result['scientific_name'] = item.contents[2].text\n",
    "        result['trend'] = item.contents[3].text\n",
    "        result['region'] = item.contents[4].text\n",
    "        result['threat_level'] = item.contents[5].get('title')\n",
    "        results.append(result)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIVER = Path('./geckodriver').absolute()\n",
    "URL = 'https://www.iucnredlist.org/search/list'\n",
    "OUTPUT_PATH = Path('./data/IUCN/scraped')\n",
    "\n",
    "# connect to browser with selenium\n",
    "driver = webdriver.Firefox(executable_path=DRIVER)\n",
    "driver.get(URL)\n",
    "# get filters\n",
    "filters = driver.find_element_by_class_name('filter')\n",
    "# filter only animals\n",
    "filter_animals(filters)\n",
    "# filter for country legends\n",
    "country_legends_items = ['Extant & Reintroduced', 'Extinct', 'Extinct & Reintroduced', 'Possibly Extinct', 'Possibly Extinct & Reintroduced']\n",
    "filter_country_legends(filters, country_legends_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data/IUCN/scraped\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = Path('./data/IUCN/scraped')\n",
    "print(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first time with click\n",
    "regions = get_regions(filters, click=True)\n",
    "num_regions = len(regions)\n",
    "# iterate all regions\n",
    "for i in range(num_regions):\n",
    "    regions = get_regions(filters)\n",
    "    click_filter(driver, regions[i], offset=True)\n",
    "    sleep(2)\n",
    "\n",
    "    # iterate over all countries per region\n",
    "    countries = get_countries(filters)\n",
    "    num_countries = len(countries)\n",
    "    for j in range(num_countries):\n",
    "        countries = get_countries(filters)\n",
    "        click_filter(driver, countries[j])\n",
    "        # todo: fix country name\n",
    "        country_name = countries[j].text.split('(')[0].rstrip()\n",
    "        # load the whole content\n",
    "        load_all(driver)\n",
    "        # extract content\n",
    "        # todo: find better method to wait for results to be loaded\n",
    "        sleep(10)\n",
    "        content = extract_content(driver)\n",
    "        # save to csv\n",
    "        file_path = (OUTPUT_PATH / country_name.replace(' ', '_')).with_suffix('.csv')\n",
    "        content.to_csv(file_path, index=False)\n",
    "        # uncheck country\n",
    "        click_filter(driver, countries[j])\n",
    "        sleep(2)\n",
    "\n",
    "    # get back to all regions\n",
    "    click_return_regions(filters)\n",
    "    sleep(2)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('DOPPThreatenedSpecies': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "1d1d6bb1def10cf8867d2cae1d892fdca23ec61e4937a1f80a9877e8fff6e6b9"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}